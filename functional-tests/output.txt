[info] welcome to sbt 1.4.1 (Red Hat, Inc. Java 11.0.11)
[info] loading settings for project functional-tests-build from plugins.sbt ...
[info] loading project definition from /spark-connector/functional-tests/project
[info] loading settings for project functional-tests from build.sbt ...
[info] set current project to spark-vertica-connector-functional-tests (in build file:/spark-connector/functional-tests/)
[info] compiling 1 Scala source to /spark-connector/functional-tests/target/scala-2.12/classes ...
[warn] /spark-connector/functional-tests/src/main/scala/com/vertica/spark/functests/EndToEndTests.scala:1409:36: abstract type T is unchecked since it is eliminated by erasure
[warn]             assert(err.isInstanceOf[T] ||
[warn]                                    ^
[warn] /spark-connector/functional-tests/src/main/scala/com/vertica/spark/functests/EndToEndTests.scala:1410:99: abstract type T is unchecked since it is eliminated by erasure
[warn]               (err.isInstanceOf[ContextError] && err.asInstanceOf[ContextError].error.isInstanceOf[T]))
[warn]                                                                                                   ^
[warn] /spark-connector/functional-tests/src/main/scala/com/vertica/spark/functests/EndToEndTests.scala:1409:19: abstract type T is unchecked since it is eliminated by erasure
[warn]             assert(err.isInstanceOf[T] ||
[warn]                   ^
[warn] /spark-connector/functional-tests/src/main/scala/com/vertica/spark/functests/EndToEndTests.scala:1415:36: abstract type T is unchecked since it is eliminated by erasure
[warn]             assert(err.isInstanceOf[T] ||
[warn]                                    ^
[warn] /spark-connector/functional-tests/src/main/scala/com/vertica/spark/functests/EndToEndTests.scala:1416:99: abstract type T is unchecked since it is eliminated by erasure
[warn]               (err.isInstanceOf[ContextError] && err.asInstanceOf[ContextError].error.isInstanceOf[T]))
[warn]                                                                                                   ^
[warn] /spark-connector/functional-tests/src/main/scala/com/vertica/spark/functests/EndToEndTests.scala:1415:19: abstract type T is unchecked since it is eliminated by erasure
[warn]             assert(err.isInstanceOf[T] ||
[warn]                   ^
[warn] there was one deprecation warning (since 2.2.0); re-run with -deprecation for details
[warn] 7 warnings found
[info] done compiling
[info] running Main 
TEST SUCCEEDED: should Create a table
TEST SUCCEEDED: should Insert integer data to table and load
TEST SUCCEEDED: should Insert integer data with param
TEST SUCCEEDED: should Insert string data to table and load
TEST SUCCEEDED: should Insert string data to table with param
TEST SUCCEEDED: should Insert mixed data to table and load
JDBC Error: A syntax error occurred

Caused by:
java.sql.SQLSyntaxErrorException: [Vertica][VJDBC](4566) ERROR: Relation "test_table" does not exist
Stack trace:
com.vertica.util.ServerErrorData.buildException(Unknown Source)
com.vertica.io.ProtocolStream.readExpectedMessage(Unknown Source)
com.vertica.dataengine.VDataEngine.prepareImpl(Unknown Source)
com.vertica.dataengine.VDataEngine.prepare(Unknown Source)
com.vertica.dataengine.VDataEngine.prepare(Unknown Source)
com.vertica.jdbc.common.SPreparedStatement.<init>(SPreparedStatement.java:310)
com.vertica.jdbc.jdbc41.S41PreparedStatement.<init>(S41PreparedStatement.java:91)
com.vertica.jdbc.jdbc42.S42PreparedStatement.<init>(S42PreparedStatement.java:77)
com.vertica.jdbc.VerticaJdbc42PreparedStatementImpl.<init>(Unknown Source)
com.vertica.jdbc.VJDBCObjectFactory.createPreparedStatement(Unknown Source)
com.vertica.jdbc.common.SConnection.prepareStatement(SConnection.java:1309)
com.vertica.jdbc.common.SConnection.prepareStatement(SConnection.java:1263)
com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.$anonfun$getPreparedStatement$2(VerticaJdbcLayer.scala:174)
com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.useConnection(VerticaJdbcLayer.scala:319)
com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.$anonfun$getPreparedStatement$1(VerticaJdbcLayer.scala:174)
scala.util.Either.flatMap(Either.scala:341)
com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.getPreparedStatement(VerticaJdbcLayer.scala:174)
com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.$anonfun$query$1(VerticaJdbcLayer.scala:206)
scala.util.Try$.apply(Try.scala:213)
com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.query(VerticaJdbcLayer.scala:206)
com.vertica.spark.functests.JDBCTests.$anonfun$new$10(JDBCTests.scala:135)
org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.flatspec.AnyFlatSpecLike$$anon$5.apply(AnyFlatSpecLike.scala:1683)
org.scalatest.TestSuite.withFixture(TestSuite.scala:196)
org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)
org.scalatest.flatspec.AnyFlatSpec.withFixture(AnyFlatSpec.scala:1685)
org.scalatest.flatspec.AnyFlatSpecLike.invokeWithFixture$1(AnyFlatSpecLike.scala:1681)
org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTest$1(AnyFlatSpecLike.scala:1693)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.flatspec.AnyFlatSpecLike.runTest(AnyFlatSpecLike.scala:1693)
org.scalatest.flatspec.AnyFlatSpecLike.runTest$(AnyFlatSpecLike.scala:1675)
com.vertica.spark.functests.JDBCTests.org$scalatest$BeforeAndAfterEach$$super$runTest(JDBCTests.scala:29)
org.scalatest.BeforeAndAfterEach.runTest(BeforeAndAfterEach.scala:234)
org.scalatest.BeforeAndAfterEach.runTest$(BeforeAndAfterEach.scala:227)
com.vertica.spark.functests.JDBCTests.runTest(JDBCTests.scala:29)
org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTests$1(AnyFlatSpecLike.scala:1751)
org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)
scala.collection.immutable.List.foreach(List.scala:431)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)
org.scalatest.flatspec.AnyFlatSpecLike.runTests(AnyFlatSpecLike.scala:1751)
org.scalatest.flatspec.AnyFlatSpecLike.runTests$(AnyFlatSpecLike.scala:1750)
org.scalatest.flatspec.AnyFlatSpec.runTests(AnyFlatSpec.scala:1685)
org.scalatest.Suite.run(Suite.scala:1112)
org.scalatest.Suite.run$(Suite.scala:1094)
org.scalatest.flatspec.AnyFlatSpec.org$scalatest$flatspec$AnyFlatSpecLike$$super$run(AnyFlatSpec.scala:1685)
org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$run$1(AnyFlatSpecLike.scala:1796)
org.scalatest.SuperEngine.runImpl(Engine.scala:535)
org.scalatest.flatspec.AnyFlatSpecLike.run(AnyFlatSpecLike.scala:1796)
org.scalatest.flatspec.AnyFlatSpecLike.run$(AnyFlatSpecLike.scala:1794)
com.vertica.spark.functests.JDBCTests.org$scalatest$BeforeAndAfterAll$$super$run(JDBCTests.scala:29)
org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)
org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)
org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)
com.vertica.spark.functests.JDBCTests.run(JDBCTests.scala:29)
Main$.runSuite(Main.scala:51)
Main$.delayedEndpoint$Main$1(Main.scala:99)
Main$delayedInit$body.apply(Main.scala:48)
scala.Function0.apply$mcV$sp(Function0.scala:39)
scala.Function0.apply$mcV$sp$(Function0.scala:39)
scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
scala.App.$anonfun$main$1$adapted(App.scala:80)
scala.collection.immutable.List.foreach(List.scala:431)
scala.App.main(App.scala:80)
scala.App.main$(App.scala:78)
Main$.main(Main.scala:48)
Main.main(Main.scala)
java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.base/java.lang.reflect.Method.invoke(Method.java:566)
sbt.Run.invokeMain(Run.scala:133)
sbt.Run.execute$1(Run.scala:82)
sbt.Run.$anonfun$runWithLoader$5(Run.scala:110)
scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
sbt.util.InterfaceUtil$$anon$1.get(InterfaceUtil.scala:17)
sbt.TrapExit$App.run(TrapExit.scala:258)
java.base/java.lang.Thread.run(Thread.java:829)
TEST SUCCEEDED: should Fail to load results from a table that doesn't exist
JDBC Data Error: Problem with statement execution.

Caused by:
java.sql.SQLDataException: [Vertica][VJDBC](3681) ERROR: Invalid input syntax for integer: "abc123"
Stack trace:
com.vertica.util.ServerErrorData.buildException(Unknown Source)
com.vertica.dataengine.VQueryExecutor.executeSimpleProtocol(Unknown Source)
com.vertica.dataengine.VQueryExecutor.execute(Unknown Source)
com.vertica.jdbc.common.SStatement.executeNoParams(SStatement.java:3349)
com.vertica.jdbc.common.SStatement.execute(SStatement.java:753)
com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.$anonfun$execute$1(VerticaJdbcLayer.scala:237)
scala.util.Try$.apply(Try.scala:213)
com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.execute(VerticaJdbcLayer.scala:225)
com.vertica.spark.functests.JDBCTests.$anonfun$new$11(JDBCTests.scala:153)
org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.flatspec.AnyFlatSpecLike$$anon$5.apply(AnyFlatSpecLike.scala:1683)
org.scalatest.TestSuite.withFixture(TestSuite.scala:196)
org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)
org.scalatest.flatspec.AnyFlatSpec.withFixture(AnyFlatSpec.scala:1685)
org.scalatest.flatspec.AnyFlatSpecLike.invokeWithFixture$1(AnyFlatSpecLike.scala:1681)
org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTest$1(AnyFlatSpecLike.scala:1693)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.flatspec.AnyFlatSpecLike.runTest(AnyFlatSpecLike.scala:1693)
org.scalatest.flatspec.AnyFlatSpecLike.runTest$(AnyFlatSpecLike.scala:1675)
com.vertica.spark.functests.JDBCTests.org$scalatest$BeforeAndAfterEach$$super$runTest(JDBCTests.scala:29)
org.scalatest.BeforeAndAfterEach.runTest(BeforeAndAfterEach.scala:234)
org.scalatest.BeforeAndAfterEach.runTest$(BeforeAndAfterEach.scala:227)
com.vertica.spark.functests.JDBCTests.runTest(JDBCTests.scala:29)
org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTests$1(AnyFlatSpecLike.scala:1751)
org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)
scala.collection.immutable.List.foreach(List.scala:431)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)
org.scalatest.flatspec.AnyFlatSpecLike.runTests(AnyFlatSpecLike.scala:1751)
org.scalatest.flatspec.AnyFlatSpecLike.runTests$(AnyFlatSpecLike.scala:1750)
org.scalatest.flatspec.AnyFlatSpec.runTests(AnyFlatSpec.scala:1685)
org.scalatest.Suite.run(Suite.scala:1112)
org.scalatest.Suite.run$(Suite.scala:1094)
org.scalatest.flatspec.AnyFlatSpec.org$scalatest$flatspec$AnyFlatSpecLike$$super$run(AnyFlatSpec.scala:1685)
org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$run$1(AnyFlatSpecLike.scala:1796)
org.scalatest.SuperEngine.runImpl(Engine.scala:535)
org.scalatest.flatspec.AnyFlatSpecLike.run(AnyFlatSpecLike.scala:1796)
org.scalatest.flatspec.AnyFlatSpecLike.run$(AnyFlatSpecLike.scala:1794)
com.vertica.spark.functests.JDBCTests.org$scalatest$BeforeAndAfterAll$$super$run(JDBCTests.scala:29)
org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)
org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)
org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)
com.vertica.spark.functests.JDBCTests.run(JDBCTests.scala:29)
Main$.runSuite(Main.scala:51)
Main$.delayedEndpoint$Main$1(Main.scala:99)
Main$delayedInit$body.apply(Main.scala:48)
scala.Function0.apply$mcV$sp(Function0.scala:39)
scala.Function0.apply$mcV$sp$(Function0.scala:39)
scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
scala.App.$anonfun$main$1$adapted(App.scala:80)
scala.collection.immutable.List.foreach(List.scala:431)
scala.App.main(App.scala:80)
scala.App.main$(App.scala:78)
Main$.main(Main.scala:48)
Main.main(Main.scala)
java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.base/java.lang.reflect.Method.invoke(Method.java:566)
sbt.Run.invokeMain(Run.scala:133)
sbt.Run.execute$1(Run.scala:82)
sbt.Run.$anonfun$runWithLoader$5(Run.scala:110)
scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
sbt.util.InterfaceUtil$$anon$1.get(InterfaceUtil.scala:17)
sbt.TrapExit$App.run(TrapExit.scala:258)
java.base/java.lang.Thread.run(Thread.java:829)
TEST SUCCEEDED: should Fail to insert results with wrong datatype
TEST SUCCEEDED: should Fail to create a table with bad syntax
A JDBC SQL exception occurred while trying to connect to Vertica. Check the JDBC properties to see if they are correct.

Caused by:
java.sql.SQLInvalidAuthorizationSpecException: [Vertica][VJDBC](3781) FATAL: Invalid username or password
Stack trace:
com.vertica.util.ServerErrorData.buildException(Unknown Source)
com.vertica.io.ProtocolStream.authenticate(Unknown Source)
com.vertica.io.ProtocolStream.initSession(Unknown Source)
com.vertica.core.VConnection.tryConnect(Unknown Source)
com.vertica.core.VConnection.connect(Unknown Source)
com.vertica.jdbc.common.BaseConnectionFactory.doConnect(BaseConnectionFactory.java:223)
com.vertica.jdbc.common.AbstractDriver.connect(AbstractDriver.java:232)
java.sql/java.sql.DriverManager.getConnection(DriverManager.java:677)
java.sql/java.sql.DriverManager.getConnection(DriverManager.java:189)
com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.$anonfun$connection$1(VerticaJdbcLayer.scala:124)
scala.util.Try$.apply(Try.scala:213)
com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.connection$lzycompute(VerticaJdbcLayer.scala:124)
com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.connection(VerticaJdbcLayer.scala:123)
com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.getStatement(VerticaJdbcLayer.scala:169)
com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.$anonfun$execute$1(VerticaJdbcLayer.scala:235)
scala.util.Try$.apply(Try.scala:213)
com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.execute(VerticaJdbcLayer.scala:225)
com.vertica.spark.functests.JDBCTests.$anonfun$new$13(JDBCTests.scala:181)
org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.flatspec.AnyFlatSpecLike$$anon$5.apply(AnyFlatSpecLike.scala:1683)
org.scalatest.TestSuite.withFixture(TestSuite.scala:196)
org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)
org.scalatest.flatspec.AnyFlatSpec.withFixture(AnyFlatSpec.scala:1685)
org.scalatest.flatspec.AnyFlatSpecLike.invokeWithFixture$1(AnyFlatSpecLike.scala:1681)
org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTest$1(AnyFlatSpecLike.scala:1693)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.flatspec.AnyFlatSpecLike.runTest(AnyFlatSpecLike.scala:1693)
org.scalatest.flatspec.AnyFlatSpecLike.runTest$(AnyFlatSpecLike.scala:1675)
com.vertica.spark.functests.JDBCTests.org$scalatest$BeforeAndAfterEach$$super$runTest(JDBCTests.scala:29)
org.scalatest.BeforeAndAfterEach.runTest(BeforeAndAfterEach.scala:234)
org.scalatest.BeforeAndAfterEach.runTest$(BeforeAndAfterEach.scala:227)
com.vertica.spark.functests.JDBCTests.runTest(JDBCTests.scala:29)
org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTests$1(AnyFlatSpecLike.scala:1751)
org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)
scala.collection.immutable.List.foreach(List.scala:431)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)
org.scalatest.flatspec.AnyFlatSpecLike.runTests(AnyFlatSpecLike.scala:1751)
org.scalatest.flatspec.AnyFlatSpecLike.runTests$(AnyFlatSpecLike.scala:1750)
org.scalatest.flatspec.AnyFlatSpec.runTests(AnyFlatSpec.scala:1685)
org.scalatest.Suite.run(Suite.scala:1112)
org.scalatest.Suite.run$(Suite.scala:1094)
org.scalatest.flatspec.AnyFlatSpec.org$scalatest$flatspec$AnyFlatSpecLike$$super$run(AnyFlatSpec.scala:1685)
org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$run$1(AnyFlatSpecLike.scala:1796)
org.scalatest.SuperEngine.runImpl(Engine.scala:535)
org.scalatest.flatspec.AnyFlatSpecLike.run(AnyFlatSpecLike.scala:1796)
org.scalatest.flatspec.AnyFlatSpecLike.run$(AnyFlatSpecLike.scala:1794)
com.vertica.spark.functests.JDBCTests.org$scalatest$BeforeAndAfterAll$$super$run(JDBCTests.scala:29)
org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)
org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)
org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)
com.vertica.spark.functests.JDBCTests.run(JDBCTests.scala:29)
Main$.runSuite(Main.scala:51)
Main$.delayedEndpoint$Main$1(Main.scala:99)
Main$delayedInit$body.apply(Main.scala:48)
scala.Function0.apply$mcV$sp(Function0.scala:39)
scala.Function0.apply$mcV$sp$(Function0.scala:39)
scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
scala.App.$anonfun$main$1$adapted(App.scala:80)
scala.collection.immutable.List.foreach(List.scala:431)
scala.App.main(App.scala:80)
scala.App.main$(App.scala:78)
Main$.main(Main.scala:48)
Main.main(Main.scala)
java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.base/java.lang.reflect.Method.invoke(Method.java:566)
sbt.Run.invokeMain(Run.scala:133)
sbt.Run.execute$1(Run.scala:82)
sbt.Run.$anonfun$runWithLoader$5(Run.scala:110)
scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
sbt.util.InterfaceUtil$$anon$1.get(InterfaceUtil.scala:17)
sbt.TrapExit$App.run(TrapExit.scala:258)
java.base/java.lang.Thread.run(Thread.java:829)
TEST SUCCEEDED: should Fail to connect to the wrong database
TEST SUCCEEDED: should create, list, and remove files from HDFS correctly
TEST SUCCEEDED: should correctly read data from HDFS
TEST SUCCEEDED: should return an error when reading and the reader is uninitialized.
TEST SUCCEEDED: should return an error when closing a read and the reader is uninitialized.
TEST SUCCEEDED: should return an error when reading and the schema has not been set in the config
TEST SUCCEEDED: should write then read a parquet file
create table testwriteload (a int)
TEST SUCCEEDED: should write then copy into vertica
create table testwritetimestamp (a timestamp)
TEST SUCCEEDED: should write a timestamp then copy into vertica
TEST SUCCEEDED: should Clean up a file
TEST SUCCEEDED: should Clean up parent unique directory
create table dftest1 (a int)
TEST SUCCEEDED: should read data from Vertica
create table dftest1 (a int)
TEST SUCCEEDED: should read data from Vertica using query option
create table dftest1 (a int)
create table dftest2 (b int)
TEST SUCCEEDED: should read data from Vertica using join
create table dftest1 (a int)
TEST SUCCEEDED: should read data from Vertica using aggregation query
create table dftest1 (a int)
TEST SUCCEEDED: should read 20 rows of data from Vertica
create table dftest1 (a int, b int)
TEST SUCCEEDED: should perform aggregations
create table dftest1 (a int, b int)
Getting count
Count: 40
Getting as1
Getting as2
Joining
TEST SUCCEEDED: should df alias and join
create table dftest1 (a int, b int, c float)
TEST SUCCEEDED: should collect results
create table dftest1 (a int, b int, c float)
TEST SUCCEEDED: should return column names
create table dftest1 (a int, b int, c float)
TEST SUCCEEDED: should sort
create table dftest1 (a int, b int, c float)
TEST SUCCEEDED: should get distinct elements
create table dftest1 (a int, b int, c float)
TEST SUCCEEDED: should drop and take
create table dftest1 (a int, b float)
TEST SUCCEEDED: should support data frame schema
create table dftest1 (a int, b float)
TEST SUCCEEDED: should support data frame projection
create table dftest1 (a int, b float)
TEST SUCCEEDED: should support data frame filter
create table dftest1(a int, b int) segmented by hash(a) all nodes;
insert into dftest1 values (0 ,0)
insert into dftest1 values (1 ,1)
insert into dftest1 values (2 ,2)
insert into dftest1 values (3 ,3)
insert into dftest1 values (4 ,4)
insert into dftest1 values (5 ,5)
insert into dftest1 values (6 ,6)
insert into dftest1 values (7 ,7)
insert into dftest1 values (8 ,8)
insert into dftest1 values (9 ,9)
insert into dftest1 values (10 ,10)
insert into dftest1 values (11 ,11)
insert into dftest1 values (12 ,12)
insert into dftest1 values (13 ,13)
insert into dftest1 values (14 ,14)
insert into dftest1 values (15 ,15)
insert into dftest1 values (16 ,16)
insert into dftest1 values (17 ,17)
insert into dftest1 values (18 ,18)
insert into dftest1 values (19 ,19)
insert into dftest1 values (20 ,20)
insert into dftest1 values (21 ,21)
insert into dftest1 values (22 ,22)
insert into dftest1 values (23 ,23)
insert into dftest1 values (24 ,24)
insert into dftest1 values (25 ,25)
insert into dftest1 values (26 ,26)
insert into dftest1 values (27 ,27)
insert into dftest1 values (28 ,28)
insert into dftest1 values (29 ,29)
insert into dftest1 values (30 ,30)
insert into dftest1 values (31 ,31)
insert into dftest1 values (32 ,32)
insert into dftest1 values (33 ,33)
insert into dftest1 values (34 ,34)
insert into dftest1 values (35 ,35)
insert into dftest1 values (36 ,36)
insert into dftest1 values (37 ,37)
insert into dftest1 values (38 ,38)
insert into dftest1 values (39 ,39)
+---+---+
|  a|  b|
+---+---+
|  0|  0|
|  1|  1|
|  2|  2|
|  3|  3|
|  4|  4|
|  5|  5|
|  6|  6|
|  7|  7|
|  8|  8|
|  9|  9|
| 10| 10|
| 11| 11|
| 12| 12|
| 13| 13|
| 14| 14|
| 15| 15|
| 16| 16|
| 17| 17|
| 18| 18|
| 19| 19|
+---+---+
only showing top 20 rows

schema =StructType(StructField(a,LongType,true), StructField(b,LongType,true))
count = 40
TEST SUCCEEDED: should load data from Vertica table that is [SEGMENTED] on [ALL] nodes
create table dftest1(a int, b int) unsegmented all nodes;
insert into dftest1 values (0 ,0)
insert into dftest1 values (1 ,1)
insert into dftest1 values (2 ,2)
insert into dftest1 values (3 ,3)
insert into dftest1 values (4 ,4)
insert into dftest1 values (5 ,5)
insert into dftest1 values (6 ,6)
insert into dftest1 values (7 ,7)
insert into dftest1 values (8 ,8)
insert into dftest1 values (9 ,9)
insert into dftest1 values (10 ,10)
insert into dftest1 values (11 ,11)
insert into dftest1 values (12 ,12)
insert into dftest1 values (13 ,13)
insert into dftest1 values (14 ,14)
insert into dftest1 values (15 ,15)
insert into dftest1 values (16 ,16)
insert into dftest1 values (17 ,17)
insert into dftest1 values (18 ,18)
insert into dftest1 values (19 ,19)
insert into dftest1 values (20 ,20)
insert into dftest1 values (21 ,21)
insert into dftest1 values (22 ,22)
insert into dftest1 values (23 ,23)
insert into dftest1 values (24 ,24)
insert into dftest1 values (25 ,25)
insert into dftest1 values (26 ,26)
insert into dftest1 values (27 ,27)
insert into dftest1 values (28 ,28)
insert into dftest1 values (29 ,29)
insert into dftest1 values (30 ,30)
insert into dftest1 values (31 ,31)
insert into dftest1 values (32 ,32)
insert into dftest1 values (33 ,33)
insert into dftest1 values (34 ,34)
insert into dftest1 values (35 ,35)
insert into dftest1 values (36 ,36)
insert into dftest1 values (37 ,37)
insert into dftest1 values (38 ,38)
insert into dftest1 values (39 ,39)
+---+---+
|  a|  b|
+---+---+
|  0|  0|
|  1|  1|
|  2|  2|
|  3|  3|
|  4|  4|
|  5|  5|
|  6|  6|
|  7|  7|
|  8|  8|
|  9|  9|
| 10| 10|
| 11| 11|
| 12| 12|
| 13| 13|
| 14| 14|
| 15| 15|
| 16| 16|
| 17| 17|
| 18| 18|
| 19| 19|
+---+---+
only showing top 20 rows

schema =StructType(StructField(a,LongType,true), StructField(b,LongType,true))
count = 40
TEST SUCCEEDED: should load data from Vertica table that is [UNSEGMENTED] on [ALL] nodes
create table if not exists t1(a int, b int) segmented by hash(a) nodes v_docker_node0001;
insert into t1 values (0 ,0)
insert into t1 values (1 ,1)
insert into t1 values (2 ,2)
insert into t1 values (3 ,3)
insert into t1 values (4 ,4)
insert into t1 values (5 ,5)
insert into t1 values (6 ,6)
insert into t1 values (7 ,7)
insert into t1 values (8 ,8)
insert into t1 values (9 ,9)
insert into t1 values (10 ,10)
insert into t1 values (11 ,11)
insert into t1 values (12 ,12)
insert into t1 values (13 ,13)
insert into t1 values (14 ,14)
insert into t1 values (15 ,15)
insert into t1 values (16 ,16)
insert into t1 values (17 ,17)
insert into t1 values (18 ,18)
insert into t1 values (19 ,19)
insert into t1 values (20 ,20)
insert into t1 values (21 ,21)
insert into t1 values (22 ,22)
insert into t1 values (23 ,23)
insert into t1 values (24 ,24)
insert into t1 values (25 ,25)
insert into t1 values (26 ,26)
insert into t1 values (27 ,27)
insert into t1 values (28 ,28)
insert into t1 values (29 ,29)
insert into t1 values (30 ,30)
insert into t1 values (31 ,31)
insert into t1 values (32 ,32)
insert into t1 values (33 ,33)
insert into t1 values (34 ,34)
insert into t1 values (35 ,35)
insert into t1 values (36 ,36)
insert into t1 values (37 ,37)
insert into t1 values (38 ,38)
insert into t1 values (39 ,39)
+---+---+
|  a|  b|
+---+---+
|  0|  0|
|  1|  1|
|  2|  2|
|  3|  3|
|  4|  4|
|  5|  5|
|  6|  6|
|  7|  7|
|  8|  8|
|  9|  9|
| 10| 10|
| 11| 11|
| 12| 12|
| 13| 13|
| 14| 14|
| 15| 15|
| 16| 16|
| 17| 17|
| 18| 18|
| 19| 19|
+---+---+
only showing top 20 rows

schema =StructType(StructField(a,LongType,true), StructField(b,LongType,true))
count = 40
+---+---+
|  a|  b|
+---+---+
|  0|  0|
|  1|  1|
|  2|  2|
|  3|  3|
|  4|  4|
|  5|  5|
|  6|  6|
|  7|  7|
|  8|  8|
|  9|  9|
| 10| 10|
| 11| 11|
| 12| 12|
| 13| 13|
| 14| 14|
| 15| 15|
| 16| 16|
| 17| 17|
| 18| 18|
| 19| 19|
+---+---+
only showing top 20 rows

schema =StructType(StructField(a,LongType,true), StructField(b,LongType,true))
count = 40
+---+---+
|  a|  b|
+---+---+
|  0|  0|
|  1|  1|
|  2|  2|
|  3|  3|
|  4|  4|
|  5|  5|
|  6|  6|
|  7|  7|
|  8|  8|
|  9|  9|
| 10| 10|
| 11| 11|
| 12| 12|
| 13| 13|
| 14| 14|
| 15| 15|
| 16| 16|
| 17| 17|
| 18| 18|
| 19| 19|
+---+---+
only showing top 20 rows

schema =StructType(StructField(a,LongType,true), StructField(b,LongType,true))
count = 40
TEST SUCCEEDED: should load data from Vertica table that is [SEGMENTED] on [SOME] nodes for [arbitrary partition number]
create table if not exists dftest1(a int, b int) segmented by hash(a) nodes v_docker_node0001;
insert into dftest1 values (0 ,0)
insert into dftest1 values (1 ,1)
insert into dftest1 values (2 ,2)
insert into dftest1 values (3 ,3)
insert into dftest1 values (4 ,4)
insert into dftest1 values (5 ,5)
insert into dftest1 values (6 ,6)
insert into dftest1 values (7 ,7)
insert into dftest1 values (8 ,8)
insert into dftest1 values (9 ,9)
insert into dftest1 values (10 ,10)
insert into dftest1 values (11 ,11)
insert into dftest1 values (12 ,12)
insert into dftest1 values (13 ,13)
insert into dftest1 values (14 ,14)
insert into dftest1 values (15 ,15)
insert into dftest1 values (16 ,16)
insert into dftest1 values (17 ,17)
insert into dftest1 values (18 ,18)
insert into dftest1 values (19 ,19)
insert into dftest1 values (20 ,20)
insert into dftest1 values (21 ,21)
insert into dftest1 values (22 ,22)
insert into dftest1 values (23 ,23)
insert into dftest1 values (24 ,24)
insert into dftest1 values (25 ,25)
insert into dftest1 values (26 ,26)
insert into dftest1 values (27 ,27)
insert into dftest1 values (28 ,28)
insert into dftest1 values (29 ,29)
insert into dftest1 values (30 ,30)
insert into dftest1 values (31 ,31)
insert into dftest1 values (32 ,32)
insert into dftest1 values (33 ,33)
insert into dftest1 values (34 ,34)
insert into dftest1 values (35 ,35)
insert into dftest1 values (36 ,36)
insert into dftest1 values (37 ,37)
insert into dftest1 values (38 ,38)
insert into dftest1 values (39 ,39)
+---+---+
|  a|  b|
+---+---+
|  0|  0|
|  1|  1|
|  2|  2|
|  3|  3|
|  4|  4|
|  5|  5|
|  6|  6|
|  7|  7|
|  8|  8|
|  9|  9|
| 10| 10|
| 11| 11|
| 12| 12|
| 13| 13|
| 14| 14|
| 15| 15|
| 16| 16|
| 17| 17|
| 18| 18|
| 19| 19|
+---+---+
only showing top 20 rows

schema =StructType(StructField(a,LongType,true), StructField(b,LongType,true))
count = 40
TEST SUCCEEDED: should load data from Vertica table that is [SEGMENTED] on [Some] nodes
create table if not exists dftest1(a int, b int) segmented by hash(a) nodes v_docker_node0001;
insert into dftest1 values (0 ,0)
insert into dftest1 values (1 ,1)
insert into dftest1 values (2 ,2)
insert into dftest1 values (3 ,3)
insert into dftest1 values (4 ,4)
insert into dftest1 values (5 ,5)
insert into dftest1 values (6 ,6)
insert into dftest1 values (7 ,7)
insert into dftest1 values (8 ,8)
insert into dftest1 values (9 ,9)
+---+---+
|  a|  b|
+---+---+
|  0|  0|
|  1|  1|
|  2|  2|
|  3|  3|
|  4|  4|
|  5|  5|
|  6|  6|
|  7|  7|
|  8|  8|
|  9|  9|
+---+---+

schema =StructType(StructField(a,LongType,true), StructField(b,LongType,true))
count = 10
TEST SUCCEEDED: should load data from Vertica table that is [UNSEGMENTED] on [Some] nodes
create table if not exists t1(a int, b int)  UNSEGMENTED node v_docker_node0001 KSAFE 0;
insert into t1 values (0 ,0)
insert into t1 values (1 ,1)
insert into t1 values (2 ,2)
insert into t1 values (3 ,3)
insert into t1 values (4 ,4)
insert into t1 values (5 ,5)
insert into t1 values (6 ,6)
insert into t1 values (7 ,7)
insert into t1 values (8 ,8)
insert into t1 values (9 ,9)
insert into t1 values (10 ,10)
insert into t1 values (11 ,11)
insert into t1 values (12 ,12)
insert into t1 values (13 ,13)
insert into t1 values (14 ,14)
insert into t1 values (15 ,15)
insert into t1 values (16 ,16)
insert into t1 values (17 ,17)
insert into t1 values (18 ,18)
insert into t1 values (19 ,19)
insert into t1 values (20 ,20)
insert into t1 values (21 ,21)
insert into t1 values (22 ,22)
insert into t1 values (23 ,23)
insert into t1 values (24 ,24)
insert into t1 values (25 ,25)
insert into t1 values (26 ,26)
insert into t1 values (27 ,27)
insert into t1 values (28 ,28)
insert into t1 values (29 ,29)
insert into t1 values (30 ,30)
insert into t1 values (31 ,31)
insert into t1 values (32 ,32)
insert into t1 values (33 ,33)
insert into t1 values (34 ,34)
insert into t1 values (35 ,35)
insert into t1 values (36 ,36)
insert into t1 values (37 ,37)
insert into t1 values (38 ,38)
insert into t1 values (39 ,39)
+---+---+
|  a|  b|
+---+---+
|  0|  0|
|  1|  1|
|  2|  2|
|  3|  3|
|  4|  4|
|  5|  5|
|  6|  6|
|  7|  7|
|  8|  8|
|  9|  9|
| 10| 10|
| 11| 11|
| 12| 12|
| 13| 13|
| 14| 14|
| 15| 15|
| 16| 16|
| 17| 17|
| 18| 18|
| 19| 19|
+---+---+
only showing top 20 rows

schema =StructType(StructField(a,LongType,true), StructField(b,LongType,true))
count = 40
+---+---+
|  a|  b|
+---+---+
|  0|  0|
|  1|  1|
|  2|  2|
|  3|  3|
|  4|  4|
|  5|  5|
|  6|  6|
|  7|  7|
|  8|  8|
|  9|  9|
| 10| 10|
| 11| 11|
| 12| 12|
| 13| 13|
| 14| 14|
| 15| 15|
| 16| 16|
| 17| 17|
| 18| 18|
| 19| 19|
+---+---+
only showing top 20 rows

schema =StructType(StructField(a,LongType,true), StructField(b,LongType,true))
count = 40
+---+---+
|  a|  b|
+---+---+
|  0|  0|
|  1|  1|
|  2|  2|
|  3|  3|
|  4|  4|
|  5|  5|
|  6|  6|
|  7|  7|
|  8|  8|
|  9|  9|
| 10| 10|
| 11| 11|
| 12| 12|
| 13| 13|
| 14| 14|
| 15| 15|
| 16| 16|
| 17| 17|
| 18| 18|
| 19| 19|
+---+---+
only showing top 20 rows

schema =StructType(StructField(a,LongType,true), StructField(b,LongType,true))
count = 40
TEST SUCCEEDED: should load data from Vertica table that is [UNSEGMENTED] on [One] nodes for [arbitrary partition number]
create table t1 (a binary, b varbinary, c long varbinary, d bytea, e raw)
+----+-------+-------+-------+-------+
|   a|      b|      c|      d|      e|
+----+-------+-------+-------+-------+
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
|[FF]|[FF FF]|[F0 0F]|[F0 0F]|[F0 0F]|
+----+-------+-------+-------+-------+
only showing top 20 rows

schema =StructType(StructField(a,BinaryType,true), StructField(b,BinaryType,true), StructField(c,BinaryType,true), StructField(d,BinaryType,true), StructField(e,BinaryType,true))
count = 40
TEST SUCCEEDED: should load data from Vertica for [all Binary data types] of Vertica
create table t1 (a boolean, b boolean)
+----+-----+
|   a|    b|
+----+-----+
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
|true|false|
+----+-----+
only showing top 20 rows

schema =StructType(StructField(a,BooleanType,true), StructField(b,BooleanType,true))
count = 40
TEST SUCCEEDED: should load data from Vertica for [all Boolean data types] of Vertica
create table t1 (a CHARACTER , b CHARACTER(10), c VARCHAR (20), d  CHARACTER VARYING(30) )
+---+-----+----+-------+
|  a|    b|   c|      d|
+---+-----+----+-------+
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
|  a|efghi|jklm|nopqrst|
+---+-----+----+-------+
only showing top 20 rows

schema =StructType(StructField(a,StringType,true), StructField(b,StringType,true), StructField(c,StringType,true), StructField(d,StringType,true))
count = 40
TEST SUCCEEDED: should load data from Vertica for [all Character data types] of Vertica
create table t1 (a DATE , b TIME (10), c TIMETZ (20), d  TIMESTAMP, e TIMESTAMPTZ , f INTERVAL DAY TO SECOND, g  INTERVAL YEAR TO MONTH  )
+----------+--------+------------------+-------------------+-------------------+-------+---+
|         a|       b|                 c|                  d|                  e|      f|  g|
+----------+--------+------------------+-------------------+-------------------+-------+---+
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
|1999-01-08|10:23:54|23:59:59.999999-14|2004-10-19 10:23:54|2004-10-19 08:23:54|1 06:00|1-6|
+----------+--------+------------------+-------------------+-------------------+-------+---+
only showing top 20 rows

schema =StructType(StructField(a,DateType,true), StructField(b,StringType,true), StructField(c,StringType,true), StructField(d,TimestampType,true), StructField(e,TimestampType,true), StructField(f,StringType,true), StructField(g,StringType,true))
count = 40
TEST SUCCEEDED: should load data from Vertica for [all Date/Time data types] of Vertica
create table t1 (a LONG VARBINARY(100) , b LONG VARCHAR  (120)  )
+----------------+------+
|               a|     b|
+----------------+------+
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
|[61 62 63 64 65]|fghijk|
+----------------+------+
only showing top 20 rows

schema =StructType(StructField(a,BinaryType,true), StructField(b,StringType,true))
count = 40
TEST SUCCEEDED: should load data from Vertica for [all Long data types] of Vertica
create table t1 (a INTEGER  , b SMALLINT , c BIGINT, d INT8     )
+---+---+---+---+
|  a|  b|  c|  d|
+---+---+---+---+
|  1|  2|  3|  4|
|  1|  2|  3|  4|
|  1|  2|  3|  4|
|  1|  2|  3|  4|
|  1|  2|  3|  4|
|  1|  2|  3|  4|
|  1|  2|  3|  4|
|  1|  2|  3|  4|
|  1|  2|  3|  4|
|  1|  2|  3|  4|
+---+---+---+---+

schema =StructType(StructField(a,LongType,true), StructField(b,LongType,true), StructField(c,LongType,true), StructField(d,LongType,true))
count = 10
TEST SUCCEEDED: should load data from Vertica for [Int data types] of Vertica
create table t1 (a DOUBLE PRECISION, b FLOAT, c FLOAT(20), d FLOAT8, e REAL    )
+---+---+---+---+---+
|  a|  b|  c|  d|  e|
+---+---+---+---+---+
|1.1|2.2|3.3|4.4|5.5|
|1.1|2.2|3.3|4.4|5.5|
|1.1|2.2|3.3|4.4|5.5|
|1.1|2.2|3.3|4.4|5.5|
|1.1|2.2|3.3|4.4|5.5|
|1.1|2.2|3.3|4.4|5.5|
|1.1|2.2|3.3|4.4|5.5|
|1.1|2.2|3.3|4.4|5.5|
|1.1|2.2|3.3|4.4|5.5|
|1.1|2.2|3.3|4.4|5.5|
+---+---+---+---+---+

schema =StructType(StructField(a,DoubleType,true), StructField(b,DoubleType,true), StructField(c,DoubleType,true), StructField(d,DoubleType,true), StructField(e,DoubleType,true))
count = 10
TEST SUCCEEDED: should load data from Vertica for [Double data types] of Vertica
create table t1 (a NUMERIC(5,2), b DECIMAL, c NUMBER, d MONEY(6,3)     )
+----+-----------------+---+-----+
|   a|                b|  c|    d|
+----+-----------------+---+-----+
|1.10|2.200000000000000|  3|4.400|
|1.10|2.200000000000000|  3|4.400|
|1.10|2.200000000000000|  3|4.400|
|1.10|2.200000000000000|  3|4.400|
|1.10|2.200000000000000|  3|4.400|
|1.10|2.200000000000000|  3|4.400|
|1.10|2.200000000000000|  3|4.400|
|1.10|2.200000000000000|  3|4.400|
|1.10|2.200000000000000|  3|4.400|
|1.10|2.200000000000000|  3|4.400|
+----+-----------------+---+-----+

schema =StructType(StructField(a,DecimalType(38,2),true), StructField(b,DecimalType(38,15),true), StructField(c,DecimalType(38,0),true), StructField(d,DecimalType(38,3),true))
count = 10
TEST SUCCEEDED: should load data from Vertica for [Numeric data types] of Vertica
create table dftest1 (a DATE, b float)
TEST SUCCEEDED: should load data from Vertica with a DATE-type pushdown filter
create table dftest1 (a varchar(10), b float)
TEST SUCCEEDED: should load data from Vertica with a String-type pushdown filter
create table dftest1 (a TIMESTAMP, b float)
+--------------------+---+
|                   a|  b|
+--------------------+---+
|2010-03-25 12:55:...|2.2|
|2010-03-25 12:55:...|2.2|
|2010-03-25 12:55:...|2.2|
|2010-03-25 12:55:...|2.2|
+--------------------+---+

TEST SUCCEEDED: should load data from Vertica with a TIMESTAMP-type pushdown filter
create table dftest1 (includeMe TIMESTAMP, excludeMe float)
+--------------------+
|           includeMe|
+--------------------+
|2010-03-25 12:47:...|
|2010-03-25 12:47:...|
|2010-03-25 12:47:...|
|2010-03-25 12:55:...|
|2010-03-25 12:55:...|
|2010-03-25 12:55:...|
|2010-03-25 12:55:...|
+--------------------+

TEST SUCCEEDED: should load data from Vertica with a column projection pushdown
create table dftest1 (includeMe TIMESTAMP, excludeMe float, meToo VARCHAR)
+--------------------+-------+
|           includeMe|  meToo|
+--------------------+-------+
|2010-03-25 12:47:...|  hello|
|2010-03-25 12:47:...|  hello|
|2010-03-25 12:47:...|  hello|
|2010-03-25 12:55:...|oatmeal|
|2010-03-25 12:55:...|oatmeal|
|2010-03-25 12:55:...|oatmeal|
|2010-03-25 12:55:...|oatmeal|
+--------------------+-------+

TEST SUCCEEDED: should load data from Vertica with multiple column projection pushdowns
create table dftest1 (includeMe TIMESTAMP, meToo float)
+--------------------+-----+
|           includeMe|meToo|
+--------------------+-----+
|2010-03-25 12:47:...|  2.2|
|2010-03-25 12:47:...|  2.2|
|2010-03-25 12:47:...|  2.2|
|2010-03-25 12:55:...|  2.2|
|2010-03-25 12:55:...|  2.2|
|2010-03-25 12:55:...|  2.2|
|2010-03-25 12:55:...|  2.2|
+--------------------+-----+

TEST SUCCEEDED: should load data from Vertica with select * projection pushdown
create table dftest1 (includeMe TIMESTAMP, meToo float)
+--------------------+-----+
|           includeMe|meToo|
+--------------------+-----+
|2010-03-25 12:47:...|  2.2|
|2010-03-25 12:47:...|  2.2|
|2010-03-25 12:47:...|  2.2|
|2010-03-25 12:55:...|  2.2|
|2010-03-25 12:55:...|  2.2|
|2010-03-25 12:55:...|  2.2|
|2010-03-25 12:55:...|  2.2|
+--------------------+-----+

TEST SUCCEEDED: should load data from Vertica with no column projection pushdown
create table dftest1 (excludeMe INTEGER, includeMe INTEGER)
TEST SUCCEEDED: should load data from Vertica with a column projection pushdown with the correct values
create table dftest1 (a INTEGER, b INTEGER)
TEST SUCCEEDED: should load data from Vertica with a filter pushdown with the correct values
create table dftest1 (a varchar, b integer)
TEST SUCCEEDED: should fetch the correct results when startsWith and endsWith functions are used
create table custom_segexpr_table (a varchar, b integer) segmented by mod(b, 3) all nodes
TEST SUCCEEDED: should fetch the correct results when custom, non-integer segmentation is used
create table test_in_clause (a varchar, b integer)
TEST SUCCEEDED: should work when using isin or in
create table dftest (f INTERVAL DAY TO SECOND, g INTERVAL YEAR TO MONTH)
TEST SUCCEEDED: should be able to handle interval types
create table dftest (f uuid)
TEST SUCCEEDED: should be able to handle the UUID type
[col1: int]
TEST SUCCEEDED: should write data to Vertica
TEST SUCCEEDED: should write int and string rows to Vertica
[col1: int]
TEST SUCCEEDED: should fail to inject SQL w/ tablename to drop table
[col1: int]
TEST SUCCEEDED: should fail to inject SQL w/ tablename using " to drop table
[col1: int]
TEST SUCCEEDED: should fail to inject SQL w/ tablename using ' to drop table
Save time=0.954 seconds.
TEST SUCCEEDED: should create a dataframe and load all 100 rows successfully for SaveMode.Overwrite
Save time=1.023 seconds.
TEST SUCCEEDED: should create a dataframe and load all 100 rows successfully for SaveMode.Append
+----------+---+-----+-----+
|       txt|  a|    b|float|
+----------+---+-----+-----+
|teststring| 12|false|  1.0|
+----------+---+-----+-----+

Save time=0.819 seconds.
TEST SUCCEEDED: should create a dataframe with different types and Overwrite mode
create table s2vdevtest03 (txt VARCHAR(1024), a INTEGER, b BOOLEAN, float FLOAT)
+----------+---+-----+-----+
|       txt|  a|    b|float|
+----------+---+-----+-----+
|teststring| 12|false|  1.0|
+----------+---+-----+-----+

Save time=0.737 seconds.
TEST SUCCEEDED: should create a dataframe with different types and Append mode
+----------+---+-----+-----+
|       txt|  a|    b|float|
+----------+---+-----+-----+
|teststring| 12|false|  1.0|
+----------+---+-----+-----+

Save time=0.976 seconds.
TEST SUCCEEDED: should save a dataframe under specified schema in Overwrite mode
create table S2VTestSchema.s2vdevtest06 (txt VARCHAR(1024), a INTEGER, b BOOLEAN, float FLOAT)
+----------+---+-----+-----+
|       txt|  a|    b|float|
+----------+---+-----+-----+
|teststring| 12|false|  1.0|
+----------+---+-----+-----+

Save time=0.883 seconds.
TEST SUCCEEDED: should save a dataframe under specified schema in Append mode
create table s2vdevtest08 (address_array VARBINARY(65000), name_string LONG VARCHAR(65000), tags_array VARBINARY(65000))
TEST SUCCEEDED: should Fail DataFrame with Complex type array
CREATE TABLE public.s2vdevtest09 (tdate DATE NOT NULL,tsymbol VARCHAR(3) NOT NULL) PARTITION BY EXTRACT (year FROM tdate)
+----------+-------+
|     tdate|tsymbol|
+----------+-------+
|2006-01-02|    AAA|
|2008-10-18|    AAA|
|2008-11-18|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
+----------+-------+

numDfRows=8
REJECTED-ROWS:  Check the log here to verify these printed.
TEST SUCCEEDED: should save date types over Vertica partitioned table.
CREATE TABLE s2vdevtest10 (a int)
+----------+-------+
|     tdate|tsymbol|
+----------+-------+
|2006-01-02|    AAA|
|2008-10-18|    AAA|
|2008-11-18|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
+----------+-------+

numDfRows=8
TEST SUCCEEDED: should reject invalid rows
CREATE TABLE s2vdevtest13 (a int, b float)
+----------+-------+
|     tdate|tsymbol|
+----------+-------+
|2006-01-02|    AAA|
|2008-10-18|    AAA|
|2008-11-18|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
+----------+-------+

numDfRows=8
TEST SUCCEEDED: should Vertica column type mismatch in Append mode.
CREATE TABLE s2vdevtest17 (a int, b float)
CREATE VIEW s2vdevtest17view as select * from s2vdevtest17
+----------+-------+
|     tdate|tsymbol|
+----------+-------+
|2006-01-02|    AAA|
|2008-10-18|    AAA|
|2008-11-18|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
+----------+-------+

numDfRows=8
TEST SUCCEEDED: should halt if table name already exists as view.
+----------+-------+
|     tdate|tsymbol|
+----------+-------+
|2006-01-02|    AAA|
|2008-10-18|    AAA|
|2008-11-18|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
+----------+-------+

numDfRows=8
TEST SUCCEEDED: should ErrorIfExists mode should save to Vertica if table does not already exist in Vertica.
CREATE TABLE s2vdevtest19 (a int, b float)
+----------+-------+
|     tdate|tsymbol|
+----------+-------+
|2006-01-02|    AAA|
|2008-10-18|    AAA|
|2008-11-18|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
+----------+-------+

numDfRows=8
TEST SUCCEEDED: should ErrorIfExists mode should NOT save to Vertica if table already exists in Vertica.
+----------+-------+
|     tdate|tsymbol|
+----------+-------+
|2006-01-02|    AAA|
|2008-10-18|    AAA|
|2008-11-18|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
+----------+-------+

numDfRows=8
TEST SUCCEEDED: should Ignore mode should save to Vertica if table does not already exist in Vertica.
CREATE TABLE s2vdevtest21 (a int, b float)
+----------+-------+
|     tdate|tsymbol|
+----------+-------+
|2006-01-02|    AAA|
|2008-10-18|    AAA|
|2008-11-18|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
+----------+-------+

numDfRows=8
TEST SUCCEEDED: should Ignore mode should NOT save to Vertica and ignores the load if table already exists in Vertica.
CREATE TABLE s2vdevtest22 (a int, b float)
+----------+-------+
|     tdate|tsymbol|
+----------+-------+
|2006-01-02|    AAA|
|2008-10-18|    AAA|
|2008-11-18|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
+----------+-------+

numDfRows=8
TEST SUCCEEDED: should Should throw clear error message if Vertica host address is not reachable.
CREATE TABLE s2vdevtest23 (a DATE, b float)
+----------+-------+
|     tdate|tsymbol|
+----------+-------+
|2006-01-02|    AAA|
|2008-10-18|    AAA|
|2008-11-18|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
+----------+-------+

numDfRows=8
TEST SUCCEEDED: should Should throw clear error message if Vertica user name or password is invalid.
CREATE TABLE s2vdevtest24 (a int, b float)
+----------+
|         c|
+----------+
|[123, 456]|
|      null|
+----------+

numDfRows=2
TEST SUCCEEDED: should Should throw clear error message if data frame contains a complex data type not supported by Vertica.
CREATE TABLE s2vdevtest25 (a int, b float)
+---+
|  c|
+---+
+---+

numDfRows=0
TEST SUCCEEDED: should Should not try to save an empty dataframe.
+----------+-------+
|     tdate|tsymbol|
+----------+-------+
|2006-01-02|    AAA|
|2008-10-18|    AAA|
|2008-11-18|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
|2008-10-16|    AAA|
+----------+-------+

numDfRows=8
TEST SUCCEEDED: should Should drop rejects table if it is empty.
Save time=1.057 seconds.
TEST SUCCEEDED: should Save a DataFrame when table name contains spaces in SaveMode.Overwrite
TEST SUCCEEDED: should Save a DataFrame when table name contains '$' in SaveMode.Overwrite
TEST SUCCEEDED: should Save a DataFrame when table name contains unicode chars in SaveMode.Overwrite
+--------------------+
|a_binary_type_of_col|
+--------------------+
|    [C0 A8 01 09 7B]|
|    [01 DE 01 09 FF]|
+--------------------+

TEST SUCCEEDED: should Save a DataFrame with BinaryType SaveMode.Overwrite
CREATE GLOBAL temp TABLE s2vdevtest33 (a boolean)
TEST SUCCEEDED: should Fail with helpful error message when trying to append to temp table.
+----+
|   a|
+----+
| 127|
|-128|
+----+

CREATE TABLE s2vdevtest34 (abc tinyint)
TEST SUCCEEDED: should Create Spark ByteType (represented as 'tinyint' in scala) as Vertica TINYINT type column.
+----------+
|        dt|
+----------+
|2016-07-05|
|1999-01-01|
|1965-02-01|
|      null|
+----------+

CREATE TABLE s2vdevtest35 (a date)
TEST SUCCEEDED: should Verify writing dateType works
+-------------------+
|                 dt|
+-------------------+
|2014-01-01 23:00:01|
+-------------------+

CREATE TABLE s2vdevtest35 (a timestamp)
TEST SUCCEEDED: should Verify writing timestamp type works
+--------------------+
|                 dec|
+--------------------+
|                1.23|
|               -1.23|
|12345678901234567...|
|                null|
+--------------------+

df.schema=StructType(StructField(dec,DecimalType(38,2),true))
CREATE TABLE s2vdevtest37 (dec  numeric(38,2))
TEST SUCCEEDED: should Verify writing decimal type works.
+--------------------+
|                 dec|
+--------------------+
|             1.23456|
|            -1.23456|
|1.234567890123456...|
+--------------------+

df.schema=StructType(StructField(dec,DoubleType,true))
CREATE TABLE s2vdevtest37 (dec double precision)
TEST SUCCEEDED: should Verify writing double type works.
+-------------------+
|              longs|
+-------------------+
|9223372036854775807|
+-------------------+

df.schema=StructType(StructField(longs,LongType,true))
CREATE TABLE s2vdevtestlong (longs  BIGINT)
TEST SUCCEEDED: should Verify long type works correctly.
+-----+
|longs|
+-----+
|  123|
+-----+

df.schema=StructType(StructField(longs,ShortType,true))
CREATE TABLE s2vdevtestshort (shorts SMALLINT)
TEST SUCCEEDED: should Verify short type works correctly.
+---+
| fl|
+---+
|123|
+---+

df.schema=StructType(StructField(fl,ShortType,true))
CREATE TABLE s2vdevtestshort (fl FLOAT)
TEST SUCCEEDED: should Fail if schema doesn't match table data type
+-----------+
|          i|
+-----------+
|        500|
|       -500|
| 2147483647|
|-2147483648|
|       null|
+-----------+

df.schema=StructType(StructField(i,IntegerType,true))
CREATE TABLE "s2vdevtest39" (i  INTEGER not null)
TEST SUCCEEDED: should Reject 1/5 of rows, and hence not pass failed_rows_percent_tolerance.  Append mode.
+-----------+
|          i|
+-----------+
|        500|
|       -500|
| 2147483647|
|-2147483648|
|       null|
+-----------+

df.schema=StructType(StructField(i,IntegerType,true))
CREATE TABLE "s2vdevtest40" (i  INTEGER not null)
TEST SUCCEEDED: should Reject 1/5 of rows, and pass failed_rows_percent_tolerance.  Append mode
Save time=1.075 seconds.
TEST SUCCEEDED: should create a dataframe and load all 100 rows successfully for SaveMode.Append when table does not exist
TEST SUCCEEDED: should fail to save DataFrame with duplicate column names if table does not exist.
TEST SUCCEEDED: should fail to save DataFrame with duplicate column names if load by name.
TEST SUCCEEDED: should fail to save a DataFrame with duplicate column names using parquet format.
TEST SUCCEEDED: should load data successfully using a custom DDL and a custom COPY column list together.
TEST SUCCEEDED: should load data successfully using a custom DDL and a default COPY column list (Load by Name).
TEST SUCCEEDED: should load data successfully using a custom DDL and a default COPY column list (Load by Position).
TEST SUCCEEDED: should load data successfully in Append mode for default DDL and default COPY column list.
TEST SUCCEEDED: should fail to save a DF with column names with spaces
TEST SUCCEEDED: should fail to save a DF if target_table_sql doesn't generate the right table
TEST SUCCEEDED: should fail to save a DF if there are syntax errors in target_table_sql
TEST SUCCEEDED: should fail to save a DF if there are syntax errors in copy_column_list
TEST SUCCEEDED: should fail to generate default copy by name and by position if cols names and count are different
+----------+
|        dt|
+----------+
|1555-07-05|
|0455-01-01|
|1822-02-01|
|      null|
+----------+

CREATE TABLE s2vdevtestoldwrite (a date)
TEST SUCCEEDED: should Verify writing old dateType works
+-------------------+
|                 dt|
+-------------------+
|1855-01-01 23:00:01|
+-------------------+

CREATE TABLE s2vdevtestoldwritetime (a timestamp)
TEST SUCCEEDED: should Verify writing old timestamp type works
[success] Total time: 151 s (02:31), completed May 11, 2021, 5:13:39 AM
